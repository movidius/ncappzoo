/*
// Copyright (c) 2018 Intel Corporation
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
*/

#include <iomanip>
#include <vector>
#include <memory>
#include <string>
#include <cstdlib>
#include <vector>

#include <opencv2/opencv.hpp>
#include <inference_engine.hpp>

using namespace InferenceEngine;

#define GREEN  '\033[1;32m'
#define RED '\033[1;31m'
#define NOCOLOR '\033[0m'
#define YELLOW '\033[1;33m'

std::vector<std::string> labels;
const unsigned int MAX_PATH = 256;


void getNetworkLabels(std::string labelsDir, std::vector<std::string>* labelsVector)
{
    char filename[MAX_PATH];
    strncpy(filename, labelsDir.c_str(), MAX_PATH);
    FILE* cat_file = fopen(filename, "r");
    if (cat_file == nullptr) {
        std::cerr << "Could not find Category file." << std::endl;
        exit(1);
    }

    char cat_line[255];
    //fgets(cat_line , 100 , cat_file); // skip the first line
    while (fgets(cat_line , 255 , cat_file) != NULL) {
        if (cat_line[strlen(cat_line) - 1] == '\n')
            cat_line[strlen(cat_line) - 1] = '\0';
        labelsVector->push_back(std::string(cat_line));
    }
    fclose (cat_file);
}


int main(int argc, char *argv[]) {
    try {
        if (argc != 4) {
            std::cout << "Usage : ./simple_classifier_cpp <path_to_model> <path_to_image> <path_to_labels>" << std::endl;
            return EXIT_FAILURE;
        }
        const std::string input_model{argv[1]};
        const std::string input_image_path{argv[2]};
        const std::string labels_file{argv[3]};

        // ---------------------Load MKLDNN Plugin for Inference Engine-----------------------------------------

		Core ie;

        // --------------------Load IR Generated by ModelOptimizer (.xml and .bin files)------------------------

        CNNNetReader network_reader;
        network_reader.ReadNetwork(input_model);
        network_reader.ReadWeights(input_model.substr(0, input_model.size() - 4) + ".bin");
        network_reader.getNetwork().setBatchSize(1);
        CNNNetwork network = network_reader.getNetwork();

        // -----------------------------Prepare input blobs-----------------------------------------------------

        auto input_info = network.getInputsInfo().begin()->second;
        auto input_name = network.getInputsInfo().begin()->first;

        input_info->setPrecision(Precision::U8);

        // ---------------------------Prepare output blobs------------------------------------------------------

        auto output_info = network.getOutputsInfo().begin()->second;
        auto output_name = network.getOutputsInfo().begin()->first;

        output_info->setPrecision(Precision::FP32);

        // -------------------------Loading model to the plugin and then infer----------------------------------

        auto executable_network = ie.LoadNetwork(network, "MYRIAD");
        auto infer_request = executable_network.CreateInferRequestPtr();

        auto input = infer_request->GetBlob(input_name);

        auto input_data = input->buffer().as<PrecisionTrait<Precision::U8>::value_type*>();

        /* Copying data from image to the input blob */
        cv::Mat image = cv::imread(input_image_path);
        
        unsigned int channels_number = input->getTensorDesc().getDims().at(1);
        unsigned int net_input_height = input->getTensorDesc().getDims().at(2);
        unsigned int net_input_width = input->getTensorDesc().getDims().at(3);
        
        cv::resize(image, image, cv::Size(net_input_height, net_input_width));

        
        size_t image_size = net_input_height * net_input_width;

        for (size_t pid = 0; pid < image_size; ++pid) {
            for (size_t ch = 0; ch < channels_number; ++ch) {
                input_data[ch * image_size + pid] = image.at<cv::Vec3b>(pid)[ch];
            }
        }

        /* Running the request synchronously */
        infer_request->Infer();

        // ---------------------------Postprocess output blobs--------------------------------------------------

        auto output = infer_request->GetBlob(output_name);
        auto output_data = output->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();

        unsigned int results_to_display = 5;
        std::vector<unsigned> results;
        /*  This is to sort output probabilities and put it to results vector */
        TopResults(results_to_display, *output, results);
        if (results.size() < results_to_display)
        {
            results_to_display = results.size();
        }
		
		////
		getNetworkLabels(labels_file, &labels);

        
        std::cout << std::endl << "\033[1;33m **********  Results  ***********\033[0m"<< std::endl << std::endl;
        for (size_t id = 0; id < results_to_display; ++id) {
            auto result = output_data[results[id]];
            std::cout << " Prediction is " << std::setprecision(1) << std::fixed << result*100 << "% "  << labels[results.at(id)] <<std::endl;
        }
        
    } catch (const std::exception & ex) {
        std::cerr << ex.what() << std::endl;
        return EXIT_FAILURE;
    }
    return EXIT_SUCCESS;
}
