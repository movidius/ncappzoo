/*
 * Gender_Age
 *
 * Contributing Authors: Tome Vang <tome.vang@intel.com>, Neal Smith <neal.p.smith@intel.com>, Heather McCabe <heather.m.mccabe@intel.com>
 *
 *
 *
 */

#include <iostream>
#include <vector>
#include <time.h>
#include <iomanip>

#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/objdetect/objdetect.hpp>

#include <inference_engine.hpp>

#define WINDOW_NAME "Ncappzoo Gender Age - OpenVINO"
#define CAM_SOURCE 0


// Location of age and gender networks
#define FACE_NETWORK_PATH "../face-detection-retail-0004.xml"
#define AGEGEN_NETWORK_PATH "../age-gender-recognition-retail-0013.xml"

// window height and width 4:3 ratio
#define WINDOW_WIDTH 1280
#define WINDOW_HEIGHT 960


using namespace cv;
using namespace InferenceEngine;

// text colors and font
const int FONT = cv::FONT_HERSHEY_PLAIN;
const int FONT_SIZE = 2;
const cv::Scalar BLUE = cv::Scalar(255, 0, 0, 255);
const cv::Scalar GREEN = cv::Scalar(0, 255, 0, 255);
const cv::Scalar PINK = Scalar(255, 80, 180, 255);
const float FACE_DET_THRESHOLD = 0.65;
const int MAX_FACES_DETECTED = 10;
const float GENDER_CONF_THRESHOLD = 60.0;

// time to wait between face detection/inferences
const double INFERENCE_INTERVAL = 0.03;
const unsigned int FEMALE_LABEL = 0;
const unsigned int MALE_LABEL = 1;

struct detectionResults{
	Mat croppedMat;
	float xmin;
	float ymin;
	float xmax;
	float ymax;
	int age = 18;
	int ageConf = 0.0;
	std::string gender;
	float genderConf = 0.0;

};


/*
 * read a network
 */
InferenceEngine::CNNNetwork readNetwork(String inputNetworkPath) {
    CNNNetReader network_reader;
    network_reader.ReadNetwork(inputNetworkPath);
    network_reader.ReadWeights(inputNetworkPath.substr(0, inputNetworkPath.size() - 4) + ".bin");
    network_reader.getNetwork().setBatchSize(1);
    CNNNetwork network = network_reader.getNetwork();
    return network;
}


/*
 * Start.
 */
int main (int argc, char** argv) {
    //
    VideoCapture capture;
    Mat imgIn;
    std::vector <detectionResults> detectedFaces; // vector used to hold results
	std::vector <cv::Scalar> resultColor;
	std::vector <std::string> resultText;
	
    int key;

    // Times for inference timer
    clock_t start_time, elapsed_time;
    
    // Set up the camera
    capture.open(CAM_SOURCE);
    capture.set(CAP_PROP_FRAME_WIDTH, WINDOW_WIDTH);
    capture.set(CAP_PROP_FRAME_HEIGHT, WINDOW_HEIGHT);
    
	const int width  = (int) capture.get(cv::CAP_PROP_FRAME_WIDTH);
	const int height = (int) capture.get(cv::CAP_PROP_FRAME_HEIGHT);

    // Set up the display window
    namedWindow(WINDOW_NAME, WINDOW_NORMAL);
    resizeWindow(WINDOW_NAME, WINDOW_WIDTH, WINDOW_HEIGHT);
    setWindowProperty(WINDOW_NAME, WND_PROP_ASPECT_RATIO, WINDOW_KEEPRATIO);
    moveWindow(WINDOW_NAME, 0, 0);


    // ---------------------Load MKLDNN Plugin for Inference Engine-----------------------------------------
    Core ie;

    // --------------------Load IR Generated by NetworkOptimizer (.xml and .bin files)------------------------
    CNNNetwork faceNetwork;
    CNNNetwork ageGenNetwork;

    // read the network from the xml file
    faceNetwork = readNetwork(FACE_NETWORK_PATH);
    ageGenNetwork = readNetwork(AGEGEN_NETWORK_PATH);
    
    // Check network input for face detection
    InputsDataMap faceInputDataMap(faceNetwork.getInputsInfo());
	OutputsDataMap faceOutputDataMap(faceNetwork.getOutputsInfo());
	if (faceInputDataMap.size() != 1 && faceOutputDataMap.size() != 1)
    	throw std::logic_error("Sample supports clean SSD network with one input and one output");

	// Check network input for age and gender
	InputsDataMap ageGenInputDataMap(ageGenNetwork.getInputsInfo());
	OutputsDataMap ageGenOutputDataMap(ageGenNetwork.getOutputsInfo());
	if (ageGenInputDataMap.size() != 1 && ageGenOutputDataMap.size() != 2)
    	throw std::logic_error("Sample supports age gender network with one input and two outputs");

    // -----------------------------Prepare input blobs-----------------------------------------------------
	InputInfo::Ptr& faceInputInfo = faceInputDataMap.begin()->second;
    faceInputInfo->setPrecision(Precision::U8);
    std::string faceInputLayerName = faceInputDataMap.begin()->first;
	faceInputInfo->setPrecision(Precision::U8);
	
	InputInfo::Ptr& ageGenInputInfo = ageGenInputDataMap.begin()->second;
    ageGenInputInfo->setPrecision(Precision::U8);
    std::string ageGenInputLayerName = ageGenInputDataMap.begin()->first;
	ageGenInputInfo->setPrecision(Precision::U8);
	
    // -----------------------------Prepare output blobs-----------------------------------------------------

	auto faceOutputInfo = faceOutputDataMap.begin()->second;
	std::string faceOutputLayerName = faceOutputDataMap.begin()->first;
	faceOutputInfo->setPrecision(Precision::FP32);

	// age gender network output setup
    auto it = ageGenOutputDataMap.begin();
	DataPtr ptrAgeOutput = (it++)->second;
	DataPtr ptrGenderOutput = (it++)->second;
	std::string ageOutputLayerName = ptrAgeOutput->getName();
	std::string genOutputLayerName = ptrGenderOutput->getName();
	for (auto& output : ageGenOutputDataMap) {
    	output.second->setPrecision(Precision::FP32);
	}

    // -------------------------Loading age/gender networks to the plugin----------------------------------
    
    // create executable network object for inference
    std::map<std::string, std::string> config = {{ PluginConfigParams::KEY_PERF_COUNT, PluginConfigParams::YES }};
    auto executableFaceNetwork = ie.LoadNetwork(faceNetwork, "MYRIAD");
    auto executableAgeGenNetwork = ie.LoadNetwork(ageGenNetwork, "MYRIAD");
    
    // create inference requests
    auto faceInferRequest = executableFaceNetwork.CreateInferRequestPtr();
    auto ageGenInferRequest = executableAgeGenNetwork.CreateInferRequestPtr();

    // set the input blobs
    auto faceInput = faceInferRequest->GetBlob(faceInputLayerName);
    auto ageGenInput = ageGenInferRequest->GetBlob(ageGenInputLayerName);
    // 
    auto faceInputData = faceInput->buffer().as<PrecisionTrait<Precision::U8>::value_type*>();
    auto ageGenInputData = ageGenInput->buffer().as<PrecisionTrait<Precision::U8>::value_type*>();


    unsigned int frame_count = 0;

    // skip a frame after this many frames. adjust this if getting laggy camera 
    const int SKIP_AFTER = 3;
    printf("\nStarting gender_age app...\n");
    printf("\nPress any key to quit.\n");
    
    // -------------------------Running the inferences----------------------------------
        // Get the current time; inferences will only be performed periodically
    start_time = clock();
    
    // main loop
    while (true) 
    {
        // Get a frame from the camera
        capture >> imgIn;
        // Skip if the frame count equals or exceeds the SKIP_AFTER value
    	if (frame_count++ >= SKIP_AFTER) {
    	    capture >> imgIn;
                frame_count = 0;
        }

        // Flip the image horizontally
        flip(imgIn, imgIn, 1);

		// check if time to do an inference
        elapsed_time = clock() - start_time;
        if ((double)elapsed_time/(double)CLOCKS_PER_SEC >= INFERENCE_INTERVAL) 
        {
        	resultColor.clear();
		    resultText.clear();
        	detectedFaces.clear();
		    
		    // get pointers to the input and output dimensions for the face detection network
			auto faceInputDims = faceInferRequest->GetBlob(faceInputLayerName)->getTensorDesc().getDims();
			auto faceOutputDims = faceInferRequest->GetBlob(faceOutputLayerName)->getTensorDesc().getDims();

			// face network input dimensions
		    unsigned int faceChannelsNumber = faceInputDims.at(1);
		    unsigned int faceInputHeight = faceInputDims.at(2);
		    unsigned int faceInputWidth = faceInputDims.at(3);
		    // face network output dimensions
		    unsigned int maxProposalCount = faceOutputDims.at(2);
		    unsigned int objectSize = faceOutputDims.at(3);
		    
		    Mat imgInput;
		    cv::resize(imgIn, imgInput, cv::Size(faceInputHeight, faceInputWidth));

		    // get the input dimensions for each network
		    size_t faceImageSize = faceInputHeight * faceInputWidth;
		    // set the input data for the age network
		    for (size_t pid = 0; pid < faceImageSize; ++pid) {
		        for (size_t ch = 0; ch < faceChannelsNumber; ++ch) {
		            faceInputData[ch * faceImageSize + pid] = imgInput.at<cv::Vec3b>(pid)[ch];
		        }
		    }

		    
		    // Running the request synchronously 
		    faceInferRequest->Infer();
		    
		    // ------------- Face detection network -----------------
		    auto faceOutput = faceInferRequest->GetBlob(faceOutputLayerName);

		    const float *detections = faceOutput->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();
		    for (unsigned int i = 0; i < maxProposalCount; i++) 
		    {
		        float image_id = detections[i * objectSize + 0];
		        if (image_id < 0) 
		        {
		            //std::cout << "Only " << i << " proposals found" << std::endl;
		            break;
		        }

		        float confidence = detections[i * objectSize + 2];

		        int xmin = (int)(detections[i * objectSize + 3] * width);
		        int ymin = (int)(detections[i * objectSize + 4] * height);
		        int xmax = (int)(detections[i * objectSize + 5] * width);
		        int ymax = (int)(detections[i * objectSize + 6] * height);

				// filter out low scores
		        if (confidence > FACE_DET_THRESHOLD) {

		            xmin = std::max(0, xmin);
		            ymin = std::max(0, ymin);
		            xmax = std::min(width, xmax);
		            ymax = std::min(height, ymax);
		            cv::Mat croppedImage = imgIn(Rect(cv::Point2f(xmin, ymin), cv::Point2f(xmax, ymax)));
		            // helper for current detection
		            detectionResults currentDetection;
		            // save the cropped image to send to age/gender
		            currentDetection.croppedMat = croppedImage;
		            // save the current face location 
		            currentDetection.xmin = xmin;
		            currentDetection.ymin = ymin;
		            currentDetection.xmax = xmax;
		            currentDetection.ymax = ymax;
		            // put image into the detected faces vector
		            detectedFaces.push_back(currentDetection);

		        }
		    }
        
		    // ------------- Age Gender network -----------------
			
		    int numInferAgeGen = detectedFaces.size();
		    
			auto ageGenInputDims = ageGenInferRequest->GetBlob(ageGenInputLayerName)->getTensorDesc().getDims();
		    
		    // age gender input dims
		    unsigned int ageGenChannelsNumber = ageGenInputDims.at(1);
		    unsigned int ageGenInputHeight = ageGenInputDims.at(2);
		    unsigned int ageGenInputWidth = ageGenInputDims.at(3);

		    size_t ageGenImageSize = ageGenInputHeight * ageGenInputWidth;
		    
		    
		    for (int i = 0; i < numInferAgeGen; i++)
		    {
		    	cv::resize(detectedFaces.at(i).croppedMat, detectedFaces.at(i).croppedMat, cv::Size(ageGenInputHeight, ageGenInputWidth));
			// set the input data for the gender network
		        for (size_t pid = 0; pid < ageGenImageSize; ++pid) 
		        {
		            for (size_t ch = 0; ch < ageGenChannelsNumber; ++ch) 
		            {
		                ageGenInputData[ch * ageGenImageSize + pid] = detectedFaces.at(i).croppedMat.at<cv::Vec3b>(pid)[ch];
		            }
		        }
		        
		        ageGenInferRequest->Infer();                
				auto ageOutput = ageGenInferRequest->GetBlob(ageOutputLayerName);
				auto ageOutputData = ageOutput->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();
			
				auto genOutput = ageGenInferRequest->GetBlob(genOutputLayerName);
				auto genOutputData = genOutput->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();

				unsigned int results_to_display = 1;
				std::vector<unsigned> ageResults;
				std::vector<unsigned> genResults;

				TopResults(results_to_display, *ageOutput, ageResults);
				TopResults(results_to_display, *genOutput, genResults);

				auto ageConf = ageOutputData[ageResults[0]]*100;
				auto genConf = genOutputData[genResults[0]]*100;		

				if (genConf > GENDER_CONF_THRESHOLD && genResults.at(0) == FEMALE_LABEL)
				{
					detectedFaces.at(i).gender = "Female";
					resultColor.push_back(PINK);
				}
				else if (genConf > GENDER_CONF_THRESHOLD && genResults.at(0) == MALE_LABEL)
				{
					detectedFaces.at(i).gender = "Male";
					resultColor.push_back(BLUE);
				}
				else 
				{
					detectedFaces.at(i).gender = "Unknown";
					resultColor.push_back(GREEN);
				}
				resultText.push_back("Age: " + std::to_string((int)(ageConf)));
				elapsed_time = clock() - start_time;

			}
			start_time = clock();				
			
        }
        
        for (unsigned int i = 0; i < detectedFaces.size(); i++)
        {
        	cv::putText(imgIn, resultText.at(i), cv::Point2f(detectedFaces.at(i).xmin, detectedFaces.at(i).ymin) , FONT, FONT_SIZE, resultColor.at(i), 2);

			cv::rectangle(imgIn, cv::Point2f(detectedFaces.at(i).xmin, detectedFaces.at(i).ymin), cv::Point2f(detectedFaces.at(i).xmax, detectedFaces.at(i).ymax), resultColor.at(i), 1);
        }
        

        // Show the image in the window
        imshow(WINDOW_NAME, imgIn);
        
        // If the user presses the break key exit the loop
        key = waitKey(1);
        if (key != -1) {
            break;
        }

    } // end main while loop

    // Close all windows
    destroyAllWindows();
    std::cout << "Finished." << std::endl;

    return 0;
}
